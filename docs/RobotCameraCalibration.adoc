= AMR-ROS2 Rob2Cam Calibration - Developer Guide
:site-section: DeveloperGuide
:toc:
:toclevels: 3
:toc-title: Table of Contents
:toc-placement: preamble
:icons: font
:sectnums:
:imagesDir: dg-images
:librariesDir: ../libraries
:stylesDir: stylesheets
:xrefstyle: full
:experimental:
:linkattrs:
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:warning-caption: :warning:
endif::[]

:url-repo: https://github.com/OmronAPAC/Omron_AMR_ROS2
:url-ug: https://github.com/OmronAPAC/Omron_AMR_ROS2/blob/master/docs/RobotCameraCalibration.adoc

Last updated: `23 November 2021` By: `Zeon`

== Authors

* Zeon Chua Feiyi (link:https://github.com/CFZeon[CFZeon])

== Getting Started
=== Description
This package streamlines the collection of odometry data from the robot and Pose from the  ArUco marker before publishing it to the handeye_4dof_ros2 package and then writes the incoming calibrated input into a .yaml config file found in the pcl_processing package.

[[prerequisites]]
=== Prerequisites

. **Omron_AMR_ROS2**
+
These sets of packages assume that you already have the Omron_AMR_ROS2 packages set up.
+
https://github.com/OmronAPAC/Omron_AMR_ROS2/blob/master/docs/DeveloperGuide.adoc[Omron_AMR_ROS2 Developer's Guide]


. **Handeye 4dof**
+
You will also need the Handeye-4dof calibration algorithm from https://github.com/QuantuMope/handeye-4dof[here]. The ROS2 implementation is included in this package. Look link:https://github.com/CFZeon/handeye_4dof_ros2[here] for instructions on how to operate it.

. **ros2_aruco**
+
The ROS2 ArUco package uses OpenCV to obtain the pose of the ArUco markers relative to the camera. You can find it link:https://github.com/JMU-ROBOTICS-VIVA/ros2_aruco[here].

== Software Design
[[architecture]]
=== Architecture
An overview of this package architecture and its dependencies is summarised in the diagram below:

image::rob2cam_architecture.png[]

=== Calibration Node

==== ArUco marker Pose Subscriber
The marker pose subscriber constantly listens for new incoming ArUco marker data.

==== AMR Status Subscriber
The status subscriber constantly listens for new incoming data from the AMR including its odometry data.

==== Store Poses Service
The store_poses service appends the current pose of the AruCo marker and the AMR to 2 separate lists when this empty service is called. 

As the AMR only provides information in x, y, theta, a conversion is done to convert it to a Pose before it is published to the handeye_4dof_ros2 node. This can be found in the quat_from_yaw() function.

On a ZED2 stereo camera, it is necessary to rotate the camera to marker orientation by -1.57, 0, -1.57 as the camera faces X forward, as opposed to Z forward. The pose should be transformed in the marker callback before it is appended into the list.

TODO: add recency check for the poses.

==== calibrated_pose Subscriber Callback

Upon receiving a valid calculation from the handeye_4dof_ros2 node, the calibration result is saved into the .yaml file in pcl_processing.

The file is read and split into its individual lines with 
`file.readlines()`

Within each line, the specific identifier i.e. `camera_roll_x_offset` is searched for and the value is then replaced by the calibrated value.

The modified lines are then written back into the file.

== Instructions on Usage
[[instructions]]
. Switch to the obstacle avoidance branch.
+
....
git switch obs_avoidance_devel
....
. Build the packages
+
....
colcon build --symlink-install
....
. Source the built packages
+
....
source install/setup.bash
....
. Ensure your host machine is running the ARCL action server. It can be launched with
+
....
ros2 launch om_aiv_util server.launch.py
....
. Run `rob2cam_calibration` package with
+
....
ros2 run rob2cam_calibration calibration_node
....
. Ensure that your camera feed is streaming properly. We used the ZED2. Instructions on running the ZED2 can be found link:https://github.com/stereolabs/zed-ros-wrapper[here]. Launch the Zed2 ROS2 nodes with
+
....
ros2 launch zed_wrapper zed2.launch.py
....
. Run the ArUco Marker Node with
+
....
ros2 run ros2_aruco aruco_node
....
. Ensure that the marker is being properly detected with
+
....
ros2 topic echo aruco_poses
....
. Finally, run the handeye-4dof node using 
+
....
ros2 run handeye_4dof_ros2 handeye_4dof_node
....
. Open a new console and type rqt.
. In the rqt interface, select store_poses service.
+
image::rqt_store_poses.png[]
. Drive the robot to a location where the camera can see the aruco marker.
. Click on the Call button in rqt.
. Repeat steps 12 and 13 until a good sample size is obtained.
. Navigate to calculate_calibration service in rqt.
. Click on the Call button in rqt.
